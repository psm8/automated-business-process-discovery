\chapter{Projekt i implementacja}

\section{Wykorzystane technologie}
\subsection{Python 3.8.1}
Do implementacji algorytmu został użyty Python. Jest to najpopularniejszy język programowania w domenie uczenia maszynowego. Wymagana jest wersja 3.8+ ze względu na użycie w implementacji metod dostępnych od tej wersji.  
\subsection{PonyGE2}
PonyGE2 \cite{Fenton_2017} jest implementacja ewolucji genetycznej w jezyku Python. Pozwala na latwa konfiguracje parametrow ewolucji genetycznej oraz latwa mozliwosc dodania wlasnych problemow oraz sposobow ewaluacji wynikow.

\begin{figure}[h]
	\centering{\includegraphics{PonyGE2-search-loop.jpg}}
	\caption{\label{fig:subcaption_example}Pętla wyszukiwania}
\end{figure}

\section{Tworzenie gramatyki procesu biznesowego}

Przy tworzeniu gramatyki procesu biznesowego ważnym jest, żeby znaleźć balans, jeśli chodzi o poziom skomplikowania zaproponowanej
gramatyki.  W pracy \cite{10.1007/978-3-540-69534-9_35} autorzy przenalizowali składniki języka BPMN pod kątem częstotliwości ich stosowania. z pracy wynika, że najczęściej stosowany elementami modelów procesu biznesowego, jeśli chodzi o bramki są: xor, and oraz pętlexe lop. Do przedstawionej poniżej gramatyki dodano także bramkę opt, czyli or jako uogólnienie bramki xor w celu uniknięcia zagnieżdżonych bramek xor. Ponadto koniecznym jest posiadanie bramki seq, która oznacza normalny przepływ procesów.

Zapis GE{\_}RANGE:n jest rozszerzenie do gramatyki zapewnianym przez PonyGE2, ktore umożliwia dodanie ilosci zmiennych, czyli GE{\_}RANGE:2 oznacza 0|1|2.
Wzorując się na  Zapis GE{\_}RANGE:dataset{\_}vars jest rozszerzenie do gramatyki zapewnianym przez PonyGE2, ktore umożliwia dodanie ilosci zmiennych odpowiadajacej ich ilosci w zbiorze danych.

\begin{figure}[!ht]
\lstset{caption=Gramatyka procesu biznesowego, captionpos=b}
\lstset{label=src:grammar, frame=single}
\begin{lstlisting}
<e> ::= <anygate>

<andgate> ::= and(<anygate><anygate>) | and(<anygate>)

<xorgate> ::= xor(<anygate><anygate>) | xor(<anygate>)

<seqgate> ::= seq(<anygate><anygate>) | seq(<anygate>)

<optgate> ::= opt(<anygate><anygate>) | opt(<andgate>) | opt(<xorgate>) | 
	      opt(<seqgate>) | opt(<longate>) | opt({<event>})

<longate> ::= lo<0_n>(<anygate><anygate>) | lo<0_n>(<andgate>) |
              lo<0_n>(<xorgate>) | lo<0_n>(<optgate>) | lo<0_n>({<event>})

<anygate> ::=  <anygate><anygate> | <andgate> | <xorgate> | <seqgate> | <optgate> | 
               <longate> | {<event>}

<event> ::= GE_RANGE:dataset_vars

<0_n> ::= GE_RANGE:2
\end{lstlisting}
\end{figure}

Przykład wygenerowanej gramatyki:
and(\{d\}opt(\{f\})and(\{a\}\{c\})lop(seq(lop(\{a\})\{e\})))

Wszystkie bramki mają nazwy tej samej długości - 3 znaki, co pozwoli na łatwiejsze parsowanie gramatyki.

longate - oznacza pętle 
Poniższy przykład pokazuje gramatykę, którą ciężko opisać przy pomocy podstawowych bramek logicznych: 
\begin{figure}[h]
	\centering{\includegraphics{Grammar-lop-example.png}}
	\caption{\label{fig:subcaption_example}Przykład problemu}
\end{figure}

Jest to możliwe za pomocą notacji: 
\{a\}and(xor(\{b\}\{c\})\{d\})\{e\}lop(\{f\}and(xor(\{b\}\{c\})\{d\})\{e\})xor(\{g\}\{h\})

Użycie powyższej notacji rodzi jednak kilka problemów, Musimy mieć produkcje 
\{a\}lo1(\{f\}and(xor(\{b\}\{c\})\{d\})\{e\})xor(\{g\}\{h\})
\clearpage

\section{Projekt systemu}

\subsubsection{Podział na moduły}

Implementację podzielone na następujące moduły:
\begin{itemize}
    \item wrappers - PonyGE2 nie jest przystosowane do zaimportowania jako biblioteka, dlatego żeby oddzielić kod PonyGE2 od naszego kodu należało rozszerzyć lub nadpisać cześć z modułów PonyGE2. Moduły, które nadpisano to params, który zawiera konfigurację aplikacji oraz grammar, gdzie dodano zmiany w jaki sposób parsowana jest podana gramatyka. 
  \item fitness{\_}functions - zawiera klasę bazowy moduł, gdzie znajduje się bazowa klasa dla obliczania metryk
  \item process{\_}discovery - moduł zawiera całą logikę obliczenia metryk
\end{itemize}


\begin{figure}[!ht]
	\centering{\includegraphics{Modules.png}}
	\caption{\label{fig:flow_chart}Podział na moduły}
\end{figure}

\subsubsection{Model}

Podział na dwie klasy przydatne na różnym etapie procesowania:

Gate:

\begin{figure}[h]
	\centering{\includegraphics[scale=0.5]{GateUML.png}}
	\caption{\label{fig:subcaption_example}Gate UML}
\end{figure}

Event group:

\begin{figure}[h]
	\centering{\includegraphics[scale=0.5]{EventUML.png}}
	\caption{\label{fig:subcaption_example}Event UML}
\end{figure}


\section{Implementacja}

\subsubsection{Ogólny schemat blokowy}
\clearpage

\begin{figure}[!ht]
	\centering{\includegraphics{Overall-flow-chart.png}}
	\caption{\label{fig:flow_chart}Ogólny schemat blokowy}
\end{figure}

\subsubsection{Parsowanie gramatyki}
Parser pozwala na przetworzenie wyników uzyskanych na drodze ewolucji gramatycznej na postać, na której łatwiej będzie operować. Rezultaty uzyskane na drodze rewolucji gramatycznej w PonyGE2 są w formie tekstowej, z którą praca byłaby niewygodna, dlatego używamy parsera, żeby otrzymać wynik w postaci drzewa obiektów Gate, którego liśćmi będą obiekty Event.
Parsując korzystamy z faktu, że przy projektowaniu gramatyki wszystkie bramki logiczne zostały oznaczone 3 literowymi symbolami, a wszystkie zdarzenia otoczone nawiasami klamrowymi. Tworząc każdy obiekt Event dodajemy informację o liczbie dzieci tego obiektu, co przyda nam się przy obliczaniu metryki precyzja.

\begin{figure}[!ht]
\lstset{caption=Parser gramatyki, captionpos=b}
\lstset{label=src:passive, frame=single}
\begin{lstlisting}
    def parsuj(wyrażenie: str) -> int:

        for i w zakresie długość_wyrażenia:
            if wyrażenia[i] == "{":
                zdarzenie := Event(wyrażenia[i + 1])
                dodaj zdarzenie do aktualnie parsowanej bramki 
                i += 2
            elif wyrażenia[i] == ")":
                return i+1
            elif i+4 < długość_wyrażenia:
                bramka := stwórz nową bramkę Gate  typu zgodnego z wyrażeniem 
                i += 3
                przeparsowane_znaki = bramka.parsuj(wyrażenie[i+4:])
                dodaj zdarzenie do aktualnie parsowanej bramki 
                i += ilość_przeparsowanych_znaków
            else:
                wyrzuć wyjątek
\end{lstlisting}
\end{figure}

\subsubsection{Obliczanie metryk}

W pierwszej kolejności obliczamy metrykę dla dopasowania. Wszystkie inne metryki są obliczane dla najlepiej dopasowanej gramatyki 
\begin{figure}[!ht]
\lstset{caption=Obliczanie metryk, captionpos=b}
\lstset{label=src:best_result, frame=single}
\begin{lstlisting}

    perfectly_aligned_logs = dict()
    cumulated_error = 0

    for elem in log_info.log.keys():
        best_local_error, events_global, best_event_group = \
            calculate_metrics_for_single_process(elem, gate, min_length, max_length, alignment_cache)

        if any(event is not None and event not in model_events_list for event in events_global):
            value, events_global = get_best_alignment(best_event_group, list(elem), dict())
            best_local_error = calculate_alignment_metric(value, len(elem), len(best_event_group))
        if best_local_error == 0:
            perfectly_aligned_logs[tuple(events_global)] = log_info.log[elem]
        add_executions(model_events_list, events_global, log_info.log[elem])
        cumulated_error += best_local_error * log_info.log[elem]

    return best_result
\end{lstlisting}
\end{figure}

\begin{figure}[!ht]
\lstset{caption=Obliczanie metryk, captionpos=b}
\lstset{label=src:best_result, frame=single}
\begin{lstlisting}

def oblicz_metryki(log_info, model, najkrótsza_dozwolona_długość, 
				   najdłuższa_dozwolona_długość, cache) -> int:
	
	stosunek_wspólnych_zdarzeń_w_logu_i_modelu := oblicz_stosunek_wspólnych_zdarzeń_w_logu_i_modelu()		   
	if stosunek_wspólnych_zdarzeń_w_logu_i_modelu < MINIMALNY_STOSUNUK_WSPÓLNYCH_ZDARZEŃ_W_LOGU_I_MODELU:
        return stosunek_wspólnych_zdarzeń_w_logu_i_modelu/10
        
    idealnie_dopasowane_logi := słownik()
    skumulowany_błąd := 0
    
	for proces w log:
      	błąd_lokalny, ścieżka = oblicz_dopasowanie(event_group, elem)
      			if błąd_lokalny < minimalny_błąd_lokalny:
          			minimalny_błąd_lokalny = błąd_lokalny
          			najlpesza_ścieżka = ścieżka
  				najlepszy_błąd_lokalny += minimalny_błąd_lokalny
               oblicz metryki odwzorowanie, precyzja, generalizacja, prostota 
               najlepszy_wynik_lokalny = suma_obliczonych_metryk / liczba_metryk
               if najlepszy_wynik_lokalny > najlepszy_wynik:
                   najlepszy_wynik = najlepszy_wynik_lokalny
	metryki := oblicz metryki 
	najlepszy_wynik := średnia ważona metryk
    return najlepszy_wynik
\end{lstlisting}
\end{figure}

\subsubsection{Obliczanie metryk dla jednego procesu}

\begin{figure}[!ht]
\lstset{caption=Obliczanie metryk dla jednego procesu, captionpos=b}
\lstset{label=src:best_result, frame=single}
\begin{lstlisting}

def oblicz_metryki_dla_jednego_procesu(process, model, najkrótsza_dozwolona_długość, 
				   najdłuższa_dozwolona_długość, cache):
    len_process = len(process)
    n = len_process
    i = 1
    min_local = -2 * n
    events_global = []
    best_event_group = []
    find = False

    while not n <= oblicz_minimalną_dozwoloną_długość(len_process, min_error_local) and \
            not n >= oblicz_maksymalną_dozwoloną_długość(len_process, min_error_local):
        best_local_alignment = -1
        if min_length <= n <= max_length:
            set_model_children_boundaries(model, n)
            routes = model.get_all_n_length_routes(n, process)

            if routes is not None and not is_struct_empty(routes):
                routes = set(routes)
                route_and_process_events_ratios = []
                for event_group in routes:
                    ratio = check_route_with_log_process(event_group, process)
                    if ratio >= 1 - 6 * params['RESULT_TOLERANCE_PERCENT']/100:
                        route_and_process_events_ratios.append((event_group, ratio))
                sorted_routes_and_ratios = sorted(route_and_process_events_ratios, key=lambda x: -x[1])
                for event_group_and_ratios in sorted_routes_and_ratios:
                    if event_group_and_ratios[1] <= 1 + min_local/len_process:
                        break
                    value, events = get_best_alignment_cached(event_group_and_ratios[0], list(process), cache)
                    if value > min_local:
                        min_local = value
                        events_global = events
                        best_event_group = event_group_and_ratios[0]
                    if value == 0:
                        find = True
                        break

                local_alignment = calculate_alignment_metric(min_local, len_process, n)
                if local_alignment > best_local_alignment:
                    best_local_alignment = local_alignment
                if find:
                    break

        n += (-i if i % 2 == 1 else i)
        i += 1

    return best_local_alignment, events_global, best_event_group
    
    	ilość_wspólnych_zdarzeń_w_logu_i_modelu = 			   
	if model_to_log_events_ratio < 1 - params['RESULT_TOLERANCE_PERCENT']/100:
        return model_to_log_events_ratio/10
	for elem w log:
		
        if najkrótsza_dozwolona_długość <= n <= najdłuższa_dozwolona_długość:
            procesy_o_dlugosci_n = model.wyszukaj_procesy_o_określonej_długości(n)
            wszystkie_procesy = model.wyszukaj_wszystkie_procesy
            wszyscy_rodzice_procesów = model.wyszukaj_wszystkich_rodziców_procesów
            if istnieją procesy_o_dlugosci_n:
                najlepszy_błąd_lokalny = 0
                for elem w log:
                    minimalny_błąd_lokalny = 1023
                    for proces w procesy_o_dlugosci_n:
                        błąd_lokalny, ścieżka = oblicz_dopasowanie(event_group, elem)
                        if błąd_lokalny < minimalny_błąd_lokalny:
                            minimalny_błąd_lokalny = błąd_lokalny
                            najlpesza_ścieżka = ścieżka
                    najlepszy_błąd_lokalny += minimalny_błąd_lokalny
               oblicz metryki odwzorowanie, precyzja, generalizacja, prostota 
               najlepszy_wynik_lokalny = suma_obliczonych_metryk / liczba_metryk
               if najlepszy_wynik_lokalny > najlepszy_wynik:
                   najlepszy_wynik = najlepszy_wynik_lokalny
	metryki := oblicz metryki 
	najlepszy_wynik := średnia ważona metryk
    return najlepszy_wynik
\end{lstlisting}
\end{figure}

\subsubsection{Wyszukiwanie w modelu procesów o określonej długości}

Algorytm rekurencyjny. Implementacja różni się w zależności od przeszukiwanej branki logicznej.
\begin{figure}[!ht]
\lstset{caption=Wyszukiwanie procesów o długości n, captionpos=b}
\lstset{label=src:get_n_length, frame=single}
\begin{lstlisting}
\end{lstlisting}
\end{figure}

\subsubsection{Obliczanie dopasowania}
Pomysł zaczerpnięty z algorytmu Needlessmann-Wunsch \cite{ea252fd3937a4a309a5e07e61e5531a7}, który jest uogólnieniem odległości Levenshteina. Rozwinięty o możliwość przeszukiwania modelu rekurencyjnie oraz o możliwość podawania listy równlogłych zdarzeń.
\begin{figure}[!ht]
\lstset{caption=Obliczanie dopasowania, captionpos=b}
\lstset{label=src:alignment_calculation, frame=single}
\begin{lstlisting}
def oblicz_dopasowanie(model, log):
    kara = {'DOPASOWANIE': 0, 'BRAK_DOPASOWANIA': -2, 'PRZERWA': -1}
    wyniki_lokalne = [None] * dlugosc_macierzy_rozwiazan
    macierz_rozwiazan = Zainicjalizuj macierz zerami
    for i in range(m):
        macierz_rozwiazan[i][0] = kara['PRZERWA'] * i
    for j in range(n):
        macierz_rozwiazan[0][j] = kara['PRZERWA'] * j
    # Wypelnij osie macierzy wlasciwymi wartosciami

    for i in range(1, m):
        if should_go_recurrent(model[i-1]):
            al_mat[i], model_results_local[i] = 
            recurrent_alignment(al_mat[i - 1], model[i - 1],
                                [x for x in substrings_of_string_reversed(log)], i)
        elif len(model[i-1]) > 1:
            al_mat[i], model_results_local[i] = 
            parallel_alignment(al_mat[i - 1], model[i - 1],
                              [x for x in substrings_of_string_reversed(log)], kara, i)
        else:
            al_mat[i][0] = al_mat[i-1][0] + penalty['PRZERWA']
            basic_alignment(al_mat, model[i - 1], log, kara, i, n)

    model_results = get_all_tracebacks(al_mat, penalty['PRZERWA'], model, 
    log, model_results_local)

    return macierz_rozwiazan[m-1] #ostatnia linijka, model_results
\end{lstlisting}
\end{figure}

\subsubsection{Znajdowanie ścieżki w modelu}
Potrzebne do obliczenia precyzji oraz generalizacji.
\begin{figure}[!ht]
\lstset{caption=Znajdowanie ścieżki w modelu, captionpos=b}
\lstset{label=src:traceback, frame=single}
\begin{lstlisting}
def znajdz_sciezke(macierz_rozwiazan, model, log, rozwiazania_podmodeli):
    sciezka = []

    while i != 0:
        event_group_full_length = len(model[i - 1])
        if model_results_local[i] is not None:
            matched_flag = False
            if array[i][j] == array[i - 1][j] + event_group_full_length * penalty_gap:
                [model_result.append(None) for _ in range(event_group_full_length)]
                array[i][j] = 0
                i -= 1

            else:
                for k in range(j):
                    processes = get_not_none(model_results_local[i][k]
                    [len(model_results_local[i][k]) - (j-k)], log)
                    if array[i][j] == array[i - 1][k] + 
                    	(event_group_full_length + (j-k) - 2 * len(processes)) * penalty_gap:
                        [model_result.append(x) for x in processes]
                        for x in processes:
                            log = log.replace(x.name, "", 1)
                        [model_result.append(None) 
                         for _ in range(event_group_full_length - len(processes))]
                        array[i][j] = 0
                        i -= 1
                        j = k
                        matched_flag = True
                        break

                if not matched_flag:
                    if array[i][j] == array[i][j - 1] + penalty_gap:
                        array[i][j] = 0
                        j -= 1

        else:
            if array[i][j] == array[i - 1][j] + penalty_gap:
                model_result.append(None)
                array[i][j] = 0
                i -= 1
            elif array[i][j] == array[i][j - 1] + penalty_gap:
                array[i][j] = 0
                j -= 1
            elif array[i][j] == array[i - 1][j - 1]:
                model_result.append(model[i-1])
                log = log.replace(model[i-1].name, "", 1)
                array[i][j] = 0
                i -= 1
                j -= 1
    return sciezka
\end{lstlisting}
\end{figure}

\subsubsection{Cache}

Wiele obliczeń się powtarza, dlatego żeby przyspieszyć działanie rezultaty są cachowane w dwóch miejscach:
Cache genotypów, dostarczane przez 
Cache obliczeń dopasowanie, które jest najbardziej kosztownym obliczeniem. Wybrane metodę cachowania LRU.  
\section{Wybór parametrów algorytmu}
